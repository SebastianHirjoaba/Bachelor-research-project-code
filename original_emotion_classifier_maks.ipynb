{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to run this notebook\n",
    "\n",
    "Note: The folders with the airlinetweets and MELD data files, as given in the course, need to be placed in the same directory with this notebook.\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "* [1. Install and import](#section1)\n",
    "* [2. Inspect the datasets](#section2)\n",
    "   * [2.2 MELD](#section2.2)\n",
    "* [3. Define the functions](#section3)\n",
    "   * [3.1 load the data](#section3.1)\n",
    "   * [3.2 convert the data to numerical representations](#section3.2)\n",
    "   * [3.3 train the classifier and get the predictions](#section3.3)\n",
    "   * [3.4 print the report](#section3.4)\n",
    "* [4. Run the functions](#section4)\n",
    "   * [4.2 Emotion analysis with MELD](#section4.2)\n",
    "* [5. Apply the trained classifiers](#section5)\n",
    "   * [5.1 Sentiment analysis trained with airli\n",
    "   * [5.2 Emotion analysis trained with MELD data](#section5.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install and import <a class=\"anchor\" id =\"section1\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/isamaks/opt/anaconda3/lib/python3.8/site-packages (1.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/isamaks/opt/anaconda3/lib/python3.8/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /Users/isamaks/opt/anaconda3/lib/python3.8/site-packages (from pandas) (1.19.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/isamaks/opt/anaconda3/lib/python3.8/site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/isamaks/opt/anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import sklearn\n",
    "import numpy\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Inspect the datasets <a class=\"anchor\" id =\"section2\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1 airlinetweets <a class=\"anchor\" id =\"section2.1\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2 MELD <a class=\"anchor\" id =\"section2.2\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "also I was the point person on my company's transition from the KL-5 to GR-6 system.\n",
      "----------------------------------------------------------------------------------------------\n",
      "   Sr No.                                          Utterance          Speaker  \\\n",
      "0       1  also I was the point person on my company's tr...         Chandler   \n",
      "1       2                   You must've had your hands full.  The Interviewer   \n",
      "2       3                            That I did. That I did.         Chandler   \n",
      "3       4      So let's talk a little bit about your duties.  The Interviewer   \n",
      "4       5                             My duties?  All right.         Chandler   \n",
      "\n",
      "    Emotion Sentiment  Dialogue_ID  Utterance_ID  Season  Episode  \\\n",
      "0   neutral   neutral            0             0       8       21   \n",
      "1   neutral   neutral            0             1       8       21   \n",
      "2   neutral   neutral            0             2       8       21   \n",
      "3   neutral   neutral            0             3       8       21   \n",
      "4  surprise  positive            0             4       8       21   \n",
      "\n",
      "      StartTime       EndTime  \n",
      "0  00:16:16,059  00:16:21,731  \n",
      "1  00:16:21,940  00:16:23,442  \n",
      "2  00:16:23,442  00:16:26,389  \n",
      "3  00:16:26,820  00:16:29,572  \n",
      "4  00:16:34,452  00:16:40,917  \n",
      "----------------------------------------------------------------------------------------------\n",
      "      Sr No.                                          Utterance   Speaker  \\\n",
      "9984   10474                                         You or me?  Chandler   \n",
      "9985   10475  I got it. Uh, Joey, women don't have Adam's ap...      Ross   \n",
      "9986   10476               You guys are messing with me, right?      Joey   \n",
      "9987   10477                                              Yeah.       All   \n",
      "9988   10478  That was a good one. For a second there, I was...      Joey   \n",
      "\n",
      "       Emotion Sentiment  Dialogue_ID  Utterance_ID  Season  Episode  \\\n",
      "9984   neutral   neutral         1038            13       2        3   \n",
      "9985   neutral   neutral         1038            14       2        3   \n",
      "9986  surprise  positive         1038            15       2        3   \n",
      "9987   neutral   neutral         1038            16       2        3   \n",
      "9988       joy  positive         1038            17       2        3   \n",
      "\n",
      "         StartTime       EndTime  \n",
      "9984  00:00:48,173  00:00:50,799  \n",
      "9985  00:00:51,009  00:00:53,594  \n",
      "9986  00:01:00,518  00:01:03,520  \n",
      "9987  00:01:05,398  00:01:07,274  \n",
      "9988  00:01:08,401  00:01:12,071  \n",
      "----------------------------------------------------------------------------------------------\n",
      "neutral     4710\n",
      "joy         1743\n",
      "surprise    1205\n",
      "anger       1109\n",
      "sadness      683\n",
      "disgust      271\n",
      "fear         268\n",
      "Name: Emotion, dtype: int64\n",
      "----------------------------------------------------------------------------------------------\n",
      "neutral     4710\n",
      "negative    2945\n",
      "positive    2334\n",
      "Name: Sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# MELD\n",
    "# the textual data of MELD are provided in MELD folder.\n",
    "# The data is separated in three structured csv files: train_sent_emo.csv, dev_sent_emo.csv, test_sent_emo.csv \n",
    "# for this type of data format, Pandas is very powerful and handy for data loading\n",
    "# https://pandas.pydata.org\n",
    "# Path to the MELD data\n",
    "filepath_MELD = 'MELD/train_sent_emo.csv'# if you wanna observe other files, change 'train' to 'dev' or 'test'\n",
    "\n",
    "# Create a dataframe object 'df_' by readig the file.\n",
    "df_MELD = pd.read_csv(filepath_MELD)\n",
    "\n",
    "# to fix encoding problems and replace the 'Utterance' columns with the clean strings\n",
    "df_MELD['Utterance'] = df_MELD['Utterance'].str.replace(\"\\x92|\\x97|\\x91|\\x93|\\x94|\\x85\", \"'\")\n",
    "\n",
    "# to print out the first cell in the 'Utterance' column to inspect it.\n",
    "print(df_MELD['Utterance'][0])\n",
    "print('----------------------------------------------------------------------------------------------')  \n",
    "# to print out the first 5 rows in the 'Utterance' column.\n",
    "print(df_MELD.head(5))\n",
    "print('----------------------------------------------------------------------------------------------')  \n",
    "# to print out the last 5 rows in the 'Utterance' column.\n",
    "print(df_MELD.tail(5))\n",
    "print('----------------------------------------------------------------------------------------------')  \n",
    "# to print out the last 5 rows in the 'Utterance' column without using print(), now much easier to read.\n",
    "df_MELD.tail(5)\n",
    "# to print out all emotion and sentiment values\n",
    "print(df_MELD['Emotion'].value_counts())\n",
    "print('----------------------------------------------------------------------------------------------')  \n",
    "# to print out all emotion and sentiment values\n",
    "print(df_MELD['Sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define the functions <a class=\"anchor\" id =\"section3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1 load the data <a class=\"anchor\" id =\"section3.1\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load MELD data\n",
    "def load_MELD_data():\n",
    "        # Path to the training data\n",
    "    filepath_MELD_train = 'MELD/train_sent_emo.csv'\n",
    "\n",
    "    # Create a dataframe object 'dftrain' by readig the file.\n",
    "    dftrain = pd.read_csv(filepath_MELD_train)\n",
    "\n",
    "    ### The data has some problematic strings with encoding problems. The next code removes some of these from the utterances\n",
    "    # Fixing encoding problems and replacing the 'Utterance' columns with the cleaned strings\n",
    "    dftrain['Utterance'] = dftrain['Utterance'].str.replace(\"\\x92|\\x97|\\x91|\\x93|\\x94|\\x85\", \"'\")\n",
    "    # Path to the test data\n",
    "    filepath_MELD_test = 'MELD/test_sent_emo.csv'\n",
    "    dftest = pd.read_csv(filepath_MELD_test)\n",
    "    dftest['Utterance'] = dftest['Utterance'].str.replace(\"\\x92|\\x97|\\x91|\\x93|\\x94|\\x85\", \"'\")\n",
    "        #to prepare the vectorization, we need to collect the sentences and labels to lists.\n",
    "    #to prepare the training data\n",
    "    training_instances=[]\n",
    "    for utterance in dftrain['Utterance']:\n",
    "        ### If your computer has performance issue, you can break the loop after 2000 instances to have less data, see the following two lines.\n",
    "        #if index==2000:\n",
    "        #    break\n",
    "        training_instances.append(utterance)\n",
    "\n",
    "    ### print the length of our list to see if al data are loaded\n",
    "    #print(len(training_instances))\n",
    "\n",
    "    training_labels = []\n",
    "    for label in dftrain['Emotion']:\n",
    "        ### the index need to be set the same as in the previous for-loop\n",
    "        #if index==2000:\n",
    "        #    break\n",
    "        training_labels.append(label)\n",
    "    ### Check if we have the same number of labels\n",
    "    #print(len(training_labels))\n",
    "\n",
    "    # to prepare the test data\n",
    "    test_instances = []\n",
    "    for utterance in dftest['Utterance']:\n",
    "        test_instances.append(utterance)\n",
    "\n",
    "    ### We use the same loop for the list of emotion labels that correspond with the vector representations of each utterance\n",
    "    test_labels = []\n",
    "    for label in dftest['Emotion']:\n",
    "        test_labels.append(label)\n",
    "    target_labels= list(set(test_labels+training_labels))\n",
    "    \n",
    "    return training_instances,test_instances,training_labels,test_labels,target_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2 convert the data to numerical representations <a class=\"anchor\" id =\"section3.2\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert MELD data to numerical representation\n",
    "def data_MELD_to_nrrepr(training_instances,test_instances,training_labels,test_labels):\n",
    "\n",
    "        \n",
    "    # Turn (utterances) train data into a vector \n",
    "    frequency_threshold = 4\n",
    "    utterance_vec =CountVectorizer(min_df=frequency_threshold, # If a token appears fewer times than this, across all documents, it will be ignored\n",
    "                                 tokenizer=nltk.word_tokenize # we use the nltk tokenizer\n",
    "                                 ) # stopwords are removed\n",
    "\n",
    "    training_count_vectors = utterance_vec.fit_transform(training_instances)\n",
    "    #print(training_count_vectors.shape)\n",
    "\n",
    "    # Convert raw frequency counts into TF-IDF values\n",
    "    # why TF-IDF? when we transfer the utterance to vectors, the CountVectorizer treat all words equally, recall BOW (bag-of-words)\n",
    "    # the disadvantage is a more frequent word, such as 'and', may get more weight than a much more informative word.\n",
    "    # TF-IDF solves this issue by giving less weight to words of high frequency that occur in many documents.\n",
    "    # an extensive explanation https://www.freecodecamp.org/news/how-to-process-textual-data-using-tf-idf-in-python-cd2bbc0a94a3/\n",
    "    #The shape remains the same but the values are now scores between zero and one.\n",
    "    tfidf_transformer = TfidfTransformer()\n",
    "    training_tfidf_vectors = tfidf_transformer.fit_transform(training_count_vectors)\n",
    "\n",
    "    # Turn test data into a vector \n",
    "    test_count_vectors = utterance_vec.transform(test_instances)\n",
    "    test_tfidf_vectors = tfidf_transformer.fit_transform(test_count_vectors)\n",
    "    \n",
    "    label_encoder = preprocessing.LabelEncoder()\n",
    "# we feed this encoder with the complete list of labels from our data, both the training and test labels\n",
    "    label_encoder.fit(training_labels+test_labels)\n",
    "    \n",
    "    training_classes = label_encoder.transform(training_labels)\n",
    "    test_classes = label_encoder.transform(test_labels)  \n",
    "    return training_tfidf_vectors,test_tfidf_vectors,training_classes,test_classes,utterance_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3 train the classifier and get the predictions <a class=\"anchor\" id =\"section3.3\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train classifier and make predictions\n",
    "def train_n_pred_clf(docs_train, y_train,docs_test):\n",
    "      # Now train the Multimoda Naive Bayes classifier with the training data,\n",
    "    # and assign the trained classifier to clf\n",
    "    clf = MultinomialNB().fit(docs_train, y_train)\n",
    "    # Now let the classifier make predictions on the test data\n",
    "    y_pred = clf.predict(docs_test)\n",
    "    # why multimoda naive bayes classifier? because we are dealing with multiple labels (three categories from airlinetweets, eight from MELD), we need a multinomial classifier\n",
    "    # we may also choose another one, SVM from sklearn: svm.LinearSVC, more info https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html\n",
    "    return y_pred,clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.4 print the report <a class=\"anchor\" id =\"section3.4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the report\n",
    "def show_report(y_test,y_pred,target_labels):\n",
    "    report = classification_report(y_test,y_pred,digits = 7)\n",
    "    print('Report')\n",
    "    print(report)\n",
    "    print('------------------------------------------------------------')\n",
    "    # recall the labels are:\n",
    "    print('Target labels')\n",
    "    print(target_labels)\n",
    "    print('------------------------------------------------------------')\n",
    "    # print the confusion matrix, \n",
    "    # Here's an example of how to read it https://www.aboutdatablog.com/post/reading-a-confusion-matrix\n",
    "    print('Confusion matrix')\n",
    "    print(sklearn.metrics.confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run the functions <a class=\"anchor\" id =\"section4\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1 Sentiment analysis with airlinetweets <a class=\"anchor\" id =\"section4.1\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2 Emotion analysis with MELD <a class=\"anchor\" id =\"section4.2\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0  0.6250000 0.0289855 0.0554017       345\n",
      "           1  0.0000000 0.0000000 0.0000000        68\n",
      "           2  0.0000000 0.0000000 0.0000000        50\n",
      "           3  0.5388889 0.2412935 0.3333333       402\n",
      "           4  0.5317944 0.9721338 0.6875000      1256\n",
      "           5  1.0000000 0.0048077 0.0095694       208\n",
      "           6  0.7179487 0.2989324 0.4221106       281\n",
      "\n",
      "    accuracy                      0.5413793      2610\n",
      "   macro avg  0.4876617 0.2208790 0.2154164      2610\n",
      "weighted avg  0.5785194 0.5413793 0.4357154      2610\n",
      "\n",
      "------------------------------------------------------------\n",
      "Target labels\n",
      "['disgust', 'neutral', 'joy', 'fear', 'sadness', 'anger', 'surprise']\n",
      "------------------------------------------------------------\n",
      "Confusion matrix\n",
      "[[  10    0    0   28  297    0   10]\n",
      " [   0    0    0    4   60    0    4]\n",
      " [   1    0    0    2   47    0    0]\n",
      " [   3    0    0   97  298    0    4]\n",
      " [   1    0    0   20 1221    0   14]\n",
      " [   1    0    0    5  200    1    1]\n",
      " [   0    0    0   24  173    0   84]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/isamaks/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/isamaks/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/isamaks/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#MELD\n",
    "training_instances,test_instances,training_labels,test_labels,target_labels_MELD=load_MELD_data()\n",
    "training_tfidf_vectors,test_tfidf_vectors,training_classes,test_classes,utterance_vec=data_MELD_to_nrrepr(training_instances,test_instances,training_labels,test_labels)\n",
    "y_pred,clf_MELD=train_n_pred_clf(training_tfidf_vectors, training_classes,test_tfidf_vectors)\n",
    "show_report(test_classes,y_pred,target_labels_MELD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Apply the trained classifiers  <a class=\"anchor\" id =\"section5\"></a> \n",
    "##### 5.1 Sentiment analysis trained with airlinetweets data <a class=\"anchor\" id =\"section5.1\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.2 Emotion analysis trained with MELD data <a class=\"anchor\" id =\"section5.2\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_emo=['Two thumbs up', \n",
    "               'I fell asleep halfway through', \n",
    "               \"We can't wait for the sequel!!\", \n",
    "               'I cannot recommend this highly enough', \n",
    "               'instant classic.', \n",
    "               'Steven Seagal was amazing.']\n",
    "gold_emo=['joy','anger','joy','joy','neutral','surprise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 4 3 4 4 3]\n",
      "Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0  0.0000000 0.0000000 0.0000000         1\n",
      "           3  0.5000000 0.3333333 0.4000000         3\n",
      "           4  0.2500000 1.0000000 0.4000000         1\n",
      "           6  0.0000000 0.0000000 0.0000000         1\n",
      "\n",
      "    accuracy                      0.3333333         6\n",
      "   macro avg  0.1875000 0.3333333 0.2000000         6\n",
      "weighted avg  0.2916667 0.3333333 0.2666667         6\n",
      "\n",
      "------------------------------------------------------------\n",
      "Target labels\n",
      "['disgust', 'neutral', 'joy', 'fear', 'sadness', 'anger', 'surprise']\n",
      "------------------------------------------------------------\n",
      "Confusion matrix\n",
      "[[0 0 1 0]\n",
      " [0 1 2 0]\n",
      " [0 0 1 0]\n",
      " [0 1 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/isamaks/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/isamaks/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/isamaks/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# We re-use airline_vec to transform it in the same way as the training data\n",
    "# recall: txt_senti_counts is a matrix of documents( or all sentences, each row is the vector representation of a sentence.) \n",
    "txt_emo_counts = utterance_vec.transform(txt_emo)\n",
    "#print(txt_senti_counts.shape)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "# we compute tf idf values\n",
    "txt_emo_tfidf = tfidf_transformer.fit_transform(txt_emo_counts)\n",
    "# have classifier make a prediction\n",
    "y_pred_emo = clf_MELD.predict(txt_emo_tfidf)\n",
    "print(y_pred_emo)\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "label_encoder.fit(target_labels_MELD)\n",
    "gold_emo_classes = label_encoder.transform(gold_emo)\n",
    "\n",
    "show_report(gold_emo_classes,y_pred_emo,target_labels_MELD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two thumbs up => neutral\n",
      "I fell asleep halfway through => neutral\n",
      "We can't wait for the sequel!! => joy\n",
      "I cannot recommend this highly enough => neutral\n",
      "instant classic. => neutral\n",
      "Steven Seagal was amazing. => joy\n"
     ]
    }
   ],
   "source": [
    "# to view which sentence gets what prediction\n",
    "for review, predicted_label in zip(txt_emo, y_pred_emo):\n",
    "    \n",
    "    print('%s => %s' % (review, \n",
    "                        label_encoder.classes_[predicted_label]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
